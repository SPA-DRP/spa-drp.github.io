---
layout: default
title:  'Mentors and Project Descriptions: Autumn 2020'
---


<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading">Autumn  2020</h2>
  <p> The following projects will be offered for the fall quarter. Note that if the same mentor is listed for several
    projects, only one of those projects will end up being offered (pending student interest). Please feel free to contact
    the student organizers with any questions.
    </p>


<h4> Peter Gao: Statistics for Data Journalism: Election Forecasting </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Experience with introductory stats (at the level of any of the intro classes)
      would help.
</li>
<li style="padding:0px;margin:0px 20px 0px;"> In this project, we'll take a look at how leading
newspapers and researchers conduct polls,
forecast elections, and calculate polling averages. If there is interest, we can work on reverse
engineering some of the methods used by publications such as FiveThirtyEight, RealClearPolitics, and the Upshot.
Finally, we'll consider the ethics of forecasting elections and using statistics in general to study our election process.
</li>
</p>

<h4> Zhaoqi Li: Statistical Illusions </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i>
      Prerequisites: </i> Motivation to think about interesting problems and readiness for the brain to be teased. Some mathematical maturity would be beneficial.
</li>
<li style="padding:0px;margin:0px 20px 0px;">
  Do you know that there is a “statistically significant” relationship between your salary and if you pee at night? Do you know that you will always wait longer than others at a bus stop? Do you know that a lot of the statistical concepts you learned in class actually don’t make sense? In this quarter-long study, we will dive into some common misconceptions about statistics and the questions of how to interpret statistics. We will touch on a wide range of statistical topics from a paradoxical view and learn the intuition behind them.
  No prior knowledge of statistics is required but motivation is encouraged.
</li>
</p>


<h4> Zhaoqi Li: Statistical Machine Learning and Data Analysis </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i>
      Prerequisites: </i>
      Knowledge of probability theory and Maximum Likelihood Estimation at
      the level of Stat 340 is preferred; some familiarity of basic programming is
       preferred;
      an enthusiasm of reading and experimenting is encouraged.
</li>
<li style="padding:0px;margin:0px 20px 0px;">
  We will discuss the relationship between statistics and machine learning, one of the most popular fields in the world, and how statistical techniques could be used in the machine learning framework. Topics may include classifiers (e.g., Decision Tree, Naive Bayes), training (what is training and the relation to likelihood inference), etc. The design could range from experimental to theoretical,
  depending on the background of the student.
</li>
</p>


<h4>Shane Lubold: Random Graphs </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Some exposure to probability. Some exposure to, or an interest in, graph theory. </li>
    <li style="padding:0px;margin:0px 20px 0px;"> In this project, we will study random graph theory and how the behavior of these graphs change as the size of the graph grows. We will focus primarily on a simple graph model with a number of interesting properties, the Erdös-Rényi model. In this simple model, we generate a graph on n nodes, where each node connects to any other node with probability p(n), which can depend on the graph size n. We will use theory and simulations to derive key properties of this model, such as the distribution of the degree of a vertex or the number of cliques of any size. We will also explore other exciting properties of this model. For example, if the ratio p*n grows at a certain rate as n gets big, then the graph will, for example, exhibit large cliques with probability 1. The proof of these ideas uses only basic statistical ideas. We will prove the conditions that guarantee this behavior and use simulations to explore how large the graphs must be the see this behavior. This project will expose students to the exciting field of random graphs and will give them a good understanding of how simple statistical tools can answer complex questions. </li>
</p>

<h4> Bryan Martin  </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
     </li>
    <li style="padding:0px;margin:0px 20px 0px;">
     </li>
</p>



<h4> Ronak Mehta: The Magical Properties of the SVD </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i>
      Prerequisites: </i>
      Linear Algebra (Math 308 or equivalent). Some statistical background, preferably at
    the level of 340.
</li>
<li style="padding:0px;margin:0px 20px 0px;">
  The singular value decomposition (SVD) of a matrix has wide relevance in virtually all areas of applied mathematics. This project will consist of three parts:
  1) a theory section containing proofs of intriguing properties about the SVD and derivations of three problems of wide importance in statistics and machine learning: principle components analysis (PCA), partial least squares (PLS), and canonical correlations analysis (CCA), all of whose solutions depend heavily on the SVD.
  2) a simulation section demonstrating the bias-variance tradeoff of using on method over another for various regression/classification tasks.
  3) a real data section in which the student interprets the features learned by these methods on a dataset of their choice.
  This project is ideal for intermediate statistics students who want to make their linear algebra skills airtight and have a strong mathematical foundation for future success in machine learning.
</li>
</p>

<h4>Anna Neufeld:  Infectious Disease Modeling  </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Some comfort in R; experience with calculus and differential equations will be useful but not required.
 </li>
    <li style="padding:0px;margin:0px 20px 0px;"> We will start by reading introductory material on SIR compartmental models for disease modeling, and will work to implement these models in R. These are deterministic differential equation models whose output depends on knowledge of various input parameters. After becoming comfortable with the models, we will discuss how statisticians estimate the parameters of these models using current outbreak data in the face of uncertainty, and how the models are then used for predictions and forecasting. The project will evolve based on the interest and statistical level of the student, but could potentially culminate in an applied COVID-19 modeling project.
</li>
</p>

<h4> Michael Pearce: History and Practice of Data Communication </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      None; some experience with R or Python may be helpful but is not required.
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
      In this course, we'll learn about the development of data communication techniques and their modern use. We'll begin by studying how people have visualized patterns in data over time, and consider how those methods reflected the computational resources available in each era. Then, we'll shift our attention to modern issues in data communication, drawing examples from the COVID-19 pandemic and 2020 US presidential election: How do practitioners effectively show complex relationships or model uncertainty? How do people mislead readers through text and figures (intentionally or otherwise)? What common pitfalls exist, and how can we avoid them? We'll finish with a data communication project based on the student's interests.
</li>
</p>


<h4>Subodh Selukar:  Introduction to Survival Analysis </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Familiarity with R or willingness to learn; background knowledge of statistics and probability at the 311 level
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
      In many applications, researchers are interested in the time it takes for an outcome of interest to occur: for example, time to death by any cause ("overall survival") is the gold standard outcome for studies in many biomedical fields. Among other characteristics, these data exhibit a special kind of missingness termed "censoring," which requires the use of different statistical methods than other data types. In this project, the student will learn about the characteristics of time-to-event (or "survival") data and basic methods for approaching these data.
</li>
</p>

<h4>Subodh Selukar: Survival Analysis with Long-Term Survivors </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
Familiarity with R; familiarity with survival analysis
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
    In the field of survival analysis, there exist applications in which it is possible for some subjects to never experience the outcome of interest. For example, effective therapies may preclude cancer patients from experiencing tumor relapse or effective programs may prevent former prisoners from re-offending. Standard methods in survival analysis require special care when a fraction of the population may be these "long-term survivors." In this project, the student will learn about the challenges of this special case of time-to-event data and methods to address them.
</li>
</p>

<h4>Subodh Selukar: Simulation-Based Design of Studies </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Comfort with R; familiarity with design of studied, data analysis, and hypothesis testing

 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
  An important aspect of study design is computing operating characteristics such as power and sample size required to achieve a desired effect. For simple studies, closed-form solutions exist to describe these characteristics, but for more complex designs, statisticians turn to simulations in order to characterize the designs. In this project, the student will explore a variety of designs and characterize them with simulations in R. This will be a hands-on project with limited reading and more coding.
</li>
</p>

<h4> Sarah Teichman: Underrepresentation in the US Census </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      An intro stats class. Some R experience is useful but not required.
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
      In this DRP project, we will learn about who is underrepresented in the US Census (this project is based on a talk given by Maria Tackett at JSM 2020).  We will use the book Differential Undercounts in the US Census (https://www.springer.com/gp/book/9783030109721) by William O’Hare as a reference to learn about motivations and methodology of the Census, as well as undercoverage by age and race.  Along the way, we will learn about topics in missing data, demography, and capture recapture methodology.  We will use the package tidycensus to work with Census data in R. We will also read sources that discuss the implications of differential undercounts in the Census.
</li>
</p>


<h4> Seth Temple: Statistical Genetics and Identity by Descent </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
None; keen interest in the biological sciences
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
We will explore many classical ways in which statistics has been employed to study heredity in humans and other organisms. For example, we will introduce the expectation-maximization algorithm to infer allele frequencies for ABO blood types and discuss Jacquard’s 9 condensed states of identity by descent. This tutorial will be very practical as we will draw many family trees to compute kinship and inbreeding coefficients. We will use UW emeritus professor Elizabeth Thompson’s monograph "Statistical Inference from Genetic Data on Pedigrees" as reading material. Depending on student interest, we may read more chapters from Thompson’s book, investigate the history of statistical genetics as it relates to the eugenics movement, or code up some computations like the path counting formula.
</li>
</p>



  <!--
  <h4>Bryan Martin: R Package Development </h4>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Familiarity with R </li>
      <li style="padding:0px;margin:0px 20px 0px;">  Reproducible statistical analysis depends on good software and coding practices. In this project, we will learn how to go from users of R packages to developers of R packages. We will also practice and implement general software developer skills, including documentation, version control, and unit testing. We will learn how to make our code robust, efficient, and user-friendly. Ideally, you will start with an idea of something you are interested in implementing as an R package, whether it be a statistical model, data analysis application, or anything else, though this is not required! </li>
  </p>
  <h4>Bryan Martin: Statistical Learning with Sparsity </h4>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> STAT 311 highly recommended, some knowledge of regression. </li>
      <li style="padding:0px;margin:0px 20px 0px;">  Many modern applications benefit from the principle of less is more. Whether due to practical computation concerns from big data, overfitting concerns from too many parameters, or estimability concerns from a small sample size, statistical models often require sparsity. Sparsity can improve our predictions, help make the patterns we observe in our data more reproducible, and give our model parameters desirable properties.

Often, sparsity is imposed through penalization, where we include a term in our model to enforce that some parameters are set equal to zero. We will learn about some of the statistical theory underlying how penalization works, and how it impacts our model output, both mathematically and computationally. We will also learn about and compare different sparsity schemes, such as lasso, group lasso, elastic net, and more. We will focus on understanding the different settings in which we might be interested in different forms of sparsity and apply these tools to real data.
</li>
</p> -->

</div>
