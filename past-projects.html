---
layout: default
title:  'Past Mentors and Project Descriptions'
---


<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading"> Winter 2023 </h2>
<h4> Ethan Ancell: Statistics in Neuroscience </h4>  
<h5> Student: David Ye</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Students should have an understanding of hypothesis testing, as well as familiarity with R and RStudio.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Neuroscience is a fascinating and rapidly moving field enabling us to better understand how the brain works. In the quest for understanding the brain, neuroscientists use special technology in experimental trials to track neuron behavior across time, and pair this data with events occurring during the experiment. Because there is so much data generated from these trials, there are lots of fascinating statistical questions to be answered when analyzing this data. In this directed reading project, students will analyze an example dataset from a real neuroscience experimental trial conducted here at UW to try and answer whether the neurons in a mouse are actually responding to external stimuli in the experiment. Broadly speaking, this directed reading program project will be an excellent opportunity for undergraduate students to try their hands at a real application of statistics in neuroscience, as well as learn about some of the difficulties of conducting hypothesis tests in environments where certain assumptions of classical hypothesis tests are not fully met.
  </li>
  </p> 


  <h4> Alex Bank: Cutting-Edge Sports Statistics </h4> 
  <h5>Student: Luke VanHouten</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Experienced with Python or R
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Have you ever wondered how an NBA player creates space for their shot? Or how an MLB slugger knows when to crush a fastball? Or maybe you wonder how a soccer player decides where to run when they are away from the ball? This project will be driven by the student and will explore cutting-edge models being used in sports statistics. We will select a research paper from a the Sloan Sports Conference and study the data and math behind the models used in the paper. We will apply the techniques we studied to implement our own model that answers a question of interest. Potential directions include (but are not limited to) spatial models for player positioning, optimizing shot selection, projecting top draft picks, and identifying inefficiencies in Vegas lines. Students who are interested in this project should look through the conference papers from various years at the link below.

    <a href="https://www.sloansportsconference.com/conference/2022-conference#research-papers">https://www.sloansportsconference.com/conference/2022-conference#research-papers</a>
  </li>
  </p> 

  <h4> Andrea Boskovic: Proportional Hazards Models </h4> 
  <h5>Student: Dante Ramirez</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Some experience in survival analysis 
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Researchers in biomedical fields are often interested in the time it takes for a particular outcome of interest to occur, i.e., time to death. Survival models, which relate the time that passes before an event occurs to some covariates, can be used to answer these questions. In this project, we will be investigating a specific type of survival models: proportional hazards models, where a unit increase in a given covariate is multiplicative with respect to the hazard rate.
  </li>
  </p> 

  <!-- <h4> Ronak Mehta: Optimization for Machine Learning </h4> 
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        First courses in linear algebra, multivariable calculus, statistics, and machine learning. Real analysis is helpful but not required.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Modern criteria for successful machine learning (ML) models include fairness, robustness to adversarial attacks, and privacy preservation. This imperative has resulted in increasingly complex optimization problems appearing in ML and a consequent need for experts in the field. This is a theory-focused project that will introduce the reader to the tools used to analyze various optimization algorithms that arise in ML. The reading will be Chapter 5 of "Learning Theory from First Principles" by Francis Bach.
  </li>
  </p> 

  <h4> Ronak Mehta: Measure Theoretic Probability </h4> 
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        First courses in linear algebra, multivariable calculus, and statistics. Real analysis is helpful but not required.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Curriculum will be based on the interests and background of the student.
  </li>
  </p>  -->

  <h4> Vydhourie R.T. Thiyageswaran: Random walks on graphs </h4> 
  <h5>Student: Noah McMahon</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Some basic exposure to probability. We would still properly review basic probability.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    We would study what a random walk is, followed by a little bit of graph theory. Finally, we would go over some examples of where thinking about random walks on graphs has been interesting approaches to solving more general problems.
  </li>
  </p> 

  <h4> Antonio Olivas: Statistical evaluation of medical tests for classification and prediction </h4> 
  <h5>Student: Sephora-Clotilde Zoro</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        None
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    In medicine, there exist many medical tests for diagnosing a disease or for learning about an individual's prognosis once a diagnosis has been established. However, how do we know how accurately those tests diagnose the diseases they are supposed to diagnose? Also, when there is more than one diagnostic test for the same disease, how do we know which one is better? Moreover, when the diagnostic test corresponds to a continuous variable, how do we know the threshold to differentiate between having or not having the disease?

In this project, we will learn how to evaluate the performance of continuous medical tests using the receiving operating characteristic (ROC) curve. The ROC curve is very popular in medicine because it conveys graphically the performance of the test. Using properties of the ROC curve, we will learn different ways of comparing two or more medical tests, and different ways of choosing the optimal threshold based on the condition of interest.

If time permits and depending on the student's interests, we can also study how to evaluate the performance of a continuous medical test when the performance and optimal threshold depends on other individual characteristics such as age and sex.
  </li>
  </p> 

  <h4> Charlie Wolock: Introduction to prediction </h4> 
  <h5>Student: Liuyixin Shao</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Basic familiarity with R, introductory statistics. Some knowledge of regression would be useful. 
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Many classical statistical methods are focused on learning associations between variables. However, we may also be interested in prediction --- making a guess about an unknown or future outcome on the basis of whatever information we have access to. In this project, we'll learn about the unique challenges of prediction. We'll discuss how to use traditional statistical methods to make predictions and start to explore more modern machine learning techniques. This project will have a strong focus on thoughtful construction and evaluation of prediction models. We will identify an interesting dataset and implement some of our own prediction procedures using R.
  </li>
  </p> 

  <h4> Nina Galanter: Introduction to Survival Analysis </h4> 
  <h5>Student: Hannah Chiu</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Some knowledge of R or another programming language, understanding of expected value and conditional probability, some familiarity with linear regression
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    In medicine and public health, we are often interested in answering questions about the time until an event occurs. For example, what is the median recovery time from some surgery? Or: does a treatment prolong the time until death for patients with a particular cancer? Because of this, Survival Analysis, which works with these time-to-event outcomes, is an important area of Biostatistics. Most time-to-event data is censored - we cannot observe the event for everyone because we lose track of some subjects or something else happens to them. In this project, we will learn about survival analysis methods for censored data, including Kaplan-Meier curves, the Logrank test, and Cox regression. We may cover other topics based on time and student interest. This project will culminate in either a real data analysis using a dataset of the student's choice or a simulation study.  
  </li>
  </p> 

  <h4></h4>

</div>

<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading"> Autumn 2022 </h2>




<h4> Vydhourie R T Thiyageswaran:  Stellaris Project </h4>
<h5> Student: Gaunyi (Victor) He </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Comfortable/strong programming skills in Python. Interests in games and networks could be useful.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    The project will mainly be coding to simulate the process of players in a game on a graph. Here is a more detailed description of the project: https://www.stat.berkeley.edu/~aldous/Research/Stel_project/stellaris_project.html
  </li>
  </p> 


  <h4> Yikun Zhang: Introduction to Density-based Clustering and its Applications </h4> 
  <h5> Student: Dongfeng Li </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/aut2022/slides/dongfeng.pdf"> Slides </a>,  <a href = "https://spa-drp.github.io/writeups/aut2022/writeups/dongfeng.pdf"> Writeup </a>.  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        STAT 311 or STAT 340 or equivalent (knowledge of basic probability and statistics), some familiarity with programming in Python or R, etc.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    In many, if not most, practical applications, the available observations do not spread evenly over the data space but are instead grouped into several clusters. This project is designed to investigate how to statistically uncover these clusters from observational (point cloud) data through density-based approaches. Such approaches, unlike the hierarchical clustering and other dissimilarity-based methods, leverage the (estimated) density from the data to define the clusters and do not require any dissimilarity metric in the clustering process. Among the family of density-based clustering approaches, we are planning to focus on mode clustering, during which the density kernel estimator and mean shift algorithm will be reviewed and discussed. Theoretically, we may study the consistency of mode clustering and its connection to the EM algorithm. Practically, we may apply the mode clustering to real-world data and present some interesting scientific analyses. Depending on the student's interest, the project can be either theory-oriented or coding-focused. We are also happy to survey more density-based clustering approaches such as DBSCAN or other clustering methods beyond the density-based domain according to any additional request from the student.
  </li>
  </p> 

  <h4> Zhaoqi Li: Introduction to Adaptive Experimental Design </h4> 
  <h5> Student: Zilin Huang </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/aut2022/slides/zilin.pdf"> Slides </a>,  <a href = "https://spa-drp.github.io/writeups/aut2022/writeups/zilin.pdf"> Writeup </a>.  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Either some mathematical maturity at the level of STAT 394, or some familiarity with Python. 
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Suppose you are in Vegas facing three lottery machines, each with a different probability of winning a prize. You would like to figure out which one wins the most, so you try out these machines. After trying out many times, you start thinking about strategies: should I find the lottery machine that has the highest probability of winning the prize and keep playing that machine, or should I find the best way to play so I could lose the least amount of money in 100 rounds? Surprisingly, these two strategies lead to different answers, and lead to two branches in multi-armed bandits. This field has close applications to large tech companies like Amazon, Google, Meta, etc, and connects between statistics, computer science, and economics. In this project, we will first review some well-known approaches in multi-armed bandits, and either give a broad overview of the latest approaches for adaptive experimental design or conduct some experiments to visualize the power of these methods depending on student's background.
  </li>
  </p> 

  <h4> Apara Venkat: Introduction to Causal Discovery </h4> 
  <h5> Student: Mandy Zhang </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Knowledge about probability distributions, conditional independence. Programming experience would be nice, but not required.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    In this project, we will take a graphical approach to learn causal relationships between different variables in a system. First, we will learn how to represent causality using Directed Acyclic Graphs (DAGs). We will cover concepts such as d-separation, Markov property, and faithfulness. We will then describe two algorithms to learn causality from observational data. The first is a constraint-based algorithm called PC (named after Peter Spirtes and Clark Glymour who first described it). The second is a score-based algorithm called Greedy Equivalence Search (GES). Then, we will find a real dataset to apply these methods. If time permits, we can explore other ideas such as computational complexity, causal sufficiency, and background knowledge.
  </li>
  </p> 

  <h4> Erin Lipman: Bayesian perspectives on probability and statistics </h4> 
  <h5> Student: Jennie Jeon </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Probability at the level of 311, and some programming experience (preferably R)
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Many of the methods we focus on in introductory statistics courses, for example confidence intervals and null hypothesis significance testing, come from the “Frequentist” philosophy of statistics which interprets probability as describing the relative frequency of a certain event over repeated trials (ex. if I flip a fair coin 100 times, about 50 of these flips will land on heads). "Bayesian" statistics on the other hand interprets probability as describing our belief and uncertainty about an event (ex. if I flip a coin once, it is equally likely to come up heads or tails). Because the Bayesian perspective views probability in terms of belief, it provides a rigorous framework for updating our belief in light of new data (ex. if I see that my coin lands on heads 100 out of 100 times, I might start to suspect that it is a fake coin where both sides are heads). In this DRP, we will learn how the Bayesian framework allows us to update our beliefs in light of new data and allows us to answer questions that we cannot answer within the frequentist percetive.
  </li>
  </p> 

  <h4> Antonio Olivas and Anand Hemmady: Introduction to Survival Analysis </h4> 
  <h5> Student: Bao Han Ngo </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/aut2022/slides/baohan.pdf"> Slides </a>,  <a href = "https://spa-drp.github.io/writeups/aut2022/writeups/baohan.pdf"> Writeup </a>.  </h5>
<h5> Student: Nathan Dennis </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/aut2022/slides/nathan.pdf"> Slides </a>,  <a href = "https://spa-drp.github.io/writeups/aut2022/writeups/nathan.pdf"> Writeup </a>.  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Familiarity with basic probability theory (random variables, distribution functions, expectation)
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    How can we understand and estimate the length of time that will elapse before some outcome of interest happens? This question is important for a wide range of applications, including (but certainly not limited to) problems in medicine and public health. To answer this question, we use tools from survival analysis. Analyzing survival data comes with a unique set of challenges that distinguish survival analysis from other fields of statistics. The most notable of these challenges is that survival data are often censored, meaning we can't see whether or when the event happened among some observations. We will first see the kind of problems that survival analysis can be used to address, with particular attention to problems involving censoring. We will then explore both parametric (e.g. MLE) and nonparametric (e.g. Kaplan Meier) methods for handling these problems, contrasting these approaches and learning about the advantages and disadvantages of each. Depending on student interest, we may also talk about the Cox regression model. We also plan to see how to compare survival curves with parametric models and the log rank test, and finally we will apply what we have learned to a particular problem (to be chosen in conjunction with the student).
  </li>
  </p> 

  <h4> Ellen Graham: Practice and Philosophy of Data Cleaning </h4> 
  <h5> Student: Joy Li </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/aut2022/slides/joy.pdf"> Slides </a>,  <a href = "https://spa-drp.github.io/writeups/aut2022/writeups/joy.pdf"> Writeup </a>.  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Basic experience with coding is a plus but not necessary
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    When doing applied statistics it is often necessary to "clean" data before analyzing them, but the details of cleaning data are often glossed over. However, the choices made during data cleaning can significantly impact the questions that cleaned data can answer. In this project, we'll discuss what it means to "clean" data and prepare it for the next stage of analysis. The project will vary based on student interest, but possible topics include: Frameworks and tools used in practice, ethics of data cleaning, common data structures, scaling tools to large datasets, missing data, and statistical considerations of choices made while cleaning. 
  </li>
  </p> 



</div>



<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading"> Spring 2022 </h2>

 <h4> Andrea Boskovic and Harshil Desai: NBA Analytics and Machine Learning
</h4> 
<h5> Student: Kobe Sarausad </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/spring2022/slides/kobe.pdf"> Slides </a>,  <a href = "https://spa-drp.github.io/writeups/spring2022/writeups/kobe.pdf"> Writeup </a>.  </h5>
<h5> Student: Pranav Natarajan </h5> 
<h5> <a href = "https://spa-drp.github.io/writeups/spring2022/slides/pranav.pdf"> Slides </a>,  <a href = "https://spa-drp.github.io/writeups/spring2022/writeups/pranav.pdf"> Writeup </a>.  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
    Some experience in R or Python; some knowledge about basketball
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
Have you ever wondered how to predict which NBA rookie will become an all star or wondered how teams choose which players to draft? In this project, we will explore NBA data to make a model that predicts something related to basketball. We will start with an introduction to basic machine learning models, learn how to implement models in R or Python, and evaluate the models we've created. Potential directions could include (but are definitely not limited to) ranking players based on box scores and advanced stats, predicting who will be the MVP, or predicting a team's odds of making the playoffs in a given year. We are willing to mentor two students!
  </li>
  </p> 


 <h4> Nina Galanter: Optimal Treatment Rules: Causal Inference and Statistical Learning
</h4>
<h5> Student: Max Bi </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/spring2022/slides/max.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2022/writeups/max.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
    Some familiarity with conditional probability, linear regression, and R
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
 In many biomedical and public health applications of statistics we are interested in determining the best treatment. However, people and their specific situations will vary and in some cases one treatment does not fit all! Instead, we can create a treatment rule which will take in a subject and their variables and predict the best treatment for them.  Optimal treatment rules involve both causal inference and statistical learning as we create rules based on estimated treatment effects. This project will first go over causal inference foundations and then explore Q-learning methods for treatment rules, which might include regression, penalized regression, or generalized additive models depending on time and the student's background. We will use R to evaluate the methods with simulated data. 
  </li>
  </p> 

<h4> Anna Neufeld and Alan Min: Introduction to Computational Biology</h4>
<h5> Student: Wei Jun Tan </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/spring2022/slides/weijun.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2022/writeups/weijun.pdf"> Writeup </a>
  </h5>
  <h5> Student: Iris Zhou </h5>
   <!-- <h5> <a href = "https://spa-drp.github.io/writeups/spring2022/slides/iris.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2022/writeups/iris.pdf"> Writeup </a>
  </h5> -->
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
Programming experience (preferably in R). Knowledge of probability distributions at the level of Math/Stat 394 or Stat 340 is preferred but not required. 
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   Given massive amounts of data available from next generation genome sequencing, sequence alignment methods are necessary to align genomic reads to reference genomes. Alignment tools make it possible to identify genetic variation and mutation leading to biological discovery.
We plan to work with the textbook "Computational Genome Analysis," by Deonier, Waterman, and Tavare (available for free online). We will start with some background reading on necessary biological context, and then we will read about statistical concepts related to sequence alignment problems that are common in modern computational biology. After gaining this necessary background, we will learn about modern algorithms for sequence alignment. We are hoping to mentor two students! 
  </li>
  </p> 

<h4> Reading and Research Opportunity on Voting </h4>
<h4> Mentors: Prof. Elena Erosheva, Michael Pearce, Prof. Conor Mayo-Wilson </h4>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  <h5> Students: Minghe (Mia) Zhang and Man (Terry) Yuan </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/spring2022/slides/mia.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2022/writeups/mia.pdf"> Writeup </a>
  </h5>
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
Prerequisites: Computational skills (R required; other knowledge and experience, e.g., with python, is desirable). Preference given to Statistics and CSE majors and to candidates with interest and possibility to continue with the project in Summer and Fall 2022
  </li>
   <li style="padding:0px;margin:0px 20px 0px;">
In peer review settings, groups or panels of experts are tasked with evaluating submissions such as grant proposals or job candidate materials. For each submission, individual input is often given as a numeric score or a letter grade. The average or median of such scores is often used to summarize the collective opinion of a panel of experts. In this project, we will consider other ways to aggregate expert opinions by drawing a parallel between panel decisions and elections or voting.

All voting procedures have two key features: types of input that are used and how these inputs are aggregated. Examples of voting procedures include majority rule, Borda rule, single transferrable vote, and majority judgement. Voting procedures matter in that a choice of voting procedure can change panel outcomes or which candidate(s) or proposal(s) are preferred. Social choice theory demonstrates that (a) no voting procedure for selection of one out of three or more choices can satisfy simultaneously a small number of natural desiderata (this result is known as Arrow's Impossibility Theorem), that (b) every voting procedure satisfy some desiderata but not others, and that (c) election outcomes can differ depending on what voting system is used. The points (a)-(c) constitute compelling reasons in favor of better understanding the influence of aggregation methods on panel-level outcomes: we will critically assess properties of voting procedures and whether these properties should be required or desired in panel opinion aggregation methods used in peer review. The project will involve applying social choice algorithms (e.g., Borda rule and Majority Judgement) to de-identified data on panel grant peer review.
  </li>
  </p> 



 
  <h4> Antonio Olivas:  Estimation for cancer screening models using deconvolution
</h4>
</h4> 
<h5> Student: Jia Zeng </h5>
<h5> 
<a href = "https://spa-drp.github.io/writeups/spring2022/slides/jia.pdf"> Slides </a>,  <a href = "https://spa-drp.github.io/writeups/spring2022/writeups/jia.pdf"> Writeup </a>.  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
   Calculus (MATH 126) and exposure to probability theory (STAT 340).
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
 Cancer screening programs are an important component for secondary cancer prevention. To understand the conditions under which a cancer screening program provides the best benefit, mathematical models are used to estimate relevant quantities using information from cancer screening trials.
In the natural history of a cancer, the time to cancer onset (subclinical) and the sojourn/latent time (time between onset and clinical appearance) are two quantities of interest, but impossible to know separately.  However, by using a screening tool we obtain some information that allow us to differentiate between these two components.
In this project we will study a mathematical model that uses information at the aggregated level from a cancer screening trial to estimate mean time to onset, mean sojourn time, and sensitivity of the screening test, via the deconvolution formula and maximum likelihood estimation.
  </li>
  </p> 

   <h4> Rrita Zejnullahi: Introduction to Human Rights Statistics
</h4>
  <h5> Student: Cindy Elder </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/spring2022/slides/cindy.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2022/writeups/cindy.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
   Some exposure to survey sampling and regression analysis.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
In this DRP project, we consider the application of statistics methodology to Human Rights. Topics include missing females, criminal justice, violence against women, hunger and poverty. By the end of the project, we will be able to describe ways that statistical methods can be applied to human rights problems and identify areas that need development of new methods. In the first half, we will read and discuss research papers. In the latter half, we will pick a paper to replicate, with the exact choice of topic at student’s discretion. This project will be mostly remote (meetings via zoom!)
  </li>
  </p> 


</div>

<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading">Winter 2022</h2>

  <h4> Medha Agarwal: Statistical Simulations </h4>
  <h5> Student: Evana Sorfina Mohd Nazri</h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/evana.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/evana.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
     STAT 311, programming experience (preferably in R/Python)
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   This project aims to explore various methods of statistical simulations; their theoretical underpinnings and practical use. We will cover methods of obtaining independent and identically distributed random samples for both continuous and discrete random variable. These include methods like inverse transform, accept-reject, ratio of uniforms, importance sampling etc. During the later parts of the project, we will delve into Markov chain Monte Carlo, a robust method of obtaining correlated random samples from any probability distribution. While MCMC is a rich area in itself (reading about it is highly encouraged), we will cover the two most popular MCMC algorithms - Metropolis-Hastings and Gibbs Sampling. Since simulations is a very programming-centric topic, the project will regularly involve coding the sampling methods covered. These will be short codes for toy examples and will not require very high programming skills.
  </li>
  </p> 

<h4> Michael Cunetta: Sabermetrics </h4>
<h5> Student: David Wang </h5>
 <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/david.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/david.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
     Familiarity with the rules of major league baseball. Some familiarity with R.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   We will read excerpts from "The Book: Playing the Percentages in Baseball" (2007) and carry out our own inference (in R) using baseball datasets. By the end of the project, we will understand core sabermetric principles, we will be critical consumers of baseball analysis, and we will be able to ask and answer our own baseball-related research questions. In April, the student and mentor will go on a field trip to T-Mobile Park to cheer on the Mariners.
  </li>
  </p> 


<h4> Nina Galanter: Optimal Treatment Rules: Causal Inference and Statistical Learning </h4>
  <h5> Student: Leah Jia </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/leah.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/leah.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
     Some familiarity with conditional probability, linear regression, and R.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   In many biomedical and public health applications of statistics we are interested in determining the best treatment. However, people and their specific situations will vary and in some cases one treatment does not fit all! Instead, we can create a treatment rule which will take in a subject and their variables and predict the best treatment for them. We want to predict this as well as possible, and so we are looking for "optimal" rules. Optimal treatment rules involve both causal inference and statistical learning as we create rules based on estimated treatment effects. This project will first go over causal inference foundations and then explore Q-learning methods for treatment rules, which might include regression, penalized regression, and support vector machines depending on time and the student's background. We will use R to evaluate the methods with simulated and real data. If there is extra time, we could look into classification-based methods or dynamic treatment regimes.
  </li>
  </p>

  <h4> Jess Kunke: Survey statistics and R </h4>
  <h5> Student: Mekias Kebede </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/mekias.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/mekias.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
     The project can be tailored based on the student's background knowledge; some prior exposure to concepts such as mean, variance, and probability would be helpful.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   How do you analyze survey data?  How do you design a survey to address a research question and account for uncertainty in the process?  What goes into designing, conducting and analyzing big government surveys like the census?  What kinds of surveys are there?  These are some of the questions we can explore together.  We can learn about some of the approaches to designing and analyzing surveys, and we can pick a data set to analyze.  The exact direction can be tailored based on student interest and background.
  </li>
  </p>

<h4> Nick Irons: Bayesian Data Analysis</h4>
  <h5> Student: Qianqian (Emma) Yu </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/qianqian.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/qianqian.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Knowledge of probability at the level of STAT 311 and some familiarity with programming.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   Bayesian statistics is a method of modeling data that synthesizes our prior beliefs about the data with the information contained in the sample to estimate model parameters. Rather than a single point estimate of a parameter, the output of a Bayesian model is a "posterior" distribution which captures the uncertainty in our inferences. Bayesian methods are at the heart of many modern data science and machine learning techniques. In this introduction to Bayesian statistics we will cover conditional distributions, Bayes' theorem, basics of Bayesian modeling, conjugate priors, MCMC sampling, and application to real dataset(s) of interest to the student in R. If time permits, possible further directions include hypothesis testing, linear regression, hierarchical models, Latent Dirichlet Allocation, and the EM algorithm for missing data. The goal of this project is to come away with an understanding of the basic conceptual and technical aspects of Bayesian inference and to get our hands dirty with real and interesting data. Possible data applications include estimating (potentially waning) COVID vaccine efficacy, estimating COVID prevalence over time in Washington state, topic modeling in NLP, or any other dataset of interest to the student.
  </li>
  </p>

  <h4> Erin Lipman: Bayesian perspectives on statistical modeling </h4>
    <h5> Student: Zhengyang (Anthony) Xu </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/anthony.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/anthony.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
     Some familiarity with multivariate linear regression will be helpful, as will some familiarity with R.  Our project can be either more technical or more conceptual depending on the background and interests of the student.

  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   Many of the methods we focus on in introductory statistics courses, for example confidence intervals and null hypothesis significance testing, come from the “Frequentist” philosophy of statistics. There is another, increasingly popular,  philosophy of statistics called “Bayesian” statistics which has its own ways of conceptualizing and analyzing data. Bayesian statistics views parameters in the world (such as the effect of a medical treatment) as random variables rather than as fixed numbers, and it focuses on synthesizing prior evidence about the distribution of a parameter with information contained in the data. The goal of this project is to gain familiarity with statistical modeling from the Bayesian perspective.
  </li>
  </p>

   <h4> Anna Neufeld: Introduction to Clinical Trials </h4>
    <h5> Student: Hisham Bhatti </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/hisham.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/hisham.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
       None.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
Drawing mainly from the textbook "Fundamentals of Clinical Trials" by Friedman et al., we will learn about the design and analysis of clinical trials, with special attention to statistical considerations and the role of statisticians. Pending the interest of the student, for the final project we will either delve into an advanced statistical topic in clinical trials, or we will do a ``case study" where we learn about a recent/current clinical trial in depth. 
  </li>
  </p>

  <h4> Sarah Teichman: Multivariate Data Analysis </h4>
      <h5> Student: Huong Ngo </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/huong.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/huong.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
     Stat 311, and linear algebra would be helpful but not necessary
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   Almost all datasets collected across disciplines are multivariate, which means that multiple variables are measured. Recent technological advances have let researchers collect datasets with hundreds or thousands of variables. Methods from introductory statistics can be used to measure the relationship between a small subset of variables, but new methods are required to consider all of the data simultaneously. Multivariate data analysis is a set of tools to visualize, explore, and make inference about this type of data. In this project, we will use the textbook "An Introduction to Applied Multivariate Analysis with R" to learn about several methods for multivariate data analysis, including principal components analysis, multidimensional scaling, and clustering. We will choose a dataset of interest at the beginning and apply each of our methods to this dataset, leading to a final data analysis and comparison across methods.
  </li>
  </p>

   <h4> Seth Temple: Statistical Genetics I: Pedigrees and Relatedness
 </h4>
       <h5> Student: Saleh Wehelie </h5>
       <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/saleh.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/saleh.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
     STAT 311, and some programming experience
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
   We will explore statistical theory and methodology as it applies to the study of (human) heredity. The overarching theme of the readings are (1) to compute measures of relatedness (kinship and inbreeding) and conditional trait (disease) risk based on known family trees and (2) to estimate relatedness given dense SNP or entire genome sequence data. Readings will follow UW emeritus professor Elizabeth Thompson’s monograph “Statistical Inference from Genetic on Pedigrees”. We will cover conditional probabilities, likelihood models, Hardy-Weinberg equilibrium, the expectation-maximization algorithm to infer allele frequencies for the ABO blood group, Wright’s path counting formula, and identity by descent. During meetings we will work through practice exercises; for 1 or 2 meetings we will go through brief hands-on labs using current research software. More details on this recurring DRP may be found here: https://sdtemple.github.io/statgen1.
  </li>
  </p>


  <h4> Drew Wise: Introduction to Nonparametric Statistics </h4>
         <h5> Student: Xinyi (Vicky) Xiang </h5>
         <h5> <a href = "https://spa-drp.github.io/writeups/win2022/slides/vicky.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2022/writeups/vicky.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
    An introductory statistics class is all that's needed. Some programming experience would be a plus.

  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
 Many of the methods studied in an introductory statistics class — z-scores and t-tests, for example — rely on assumptions not always met by the data. The purpose of this project is to expose the student to nonparametric statistical tests, a class of techniques that are more broadly applicable. We will begin by discussing the advantages and disadvantages of nonparametric tests, and then we will study the tests themselves: Wilcoxon signed-rank tests, Mann-Whitney U-tests, and Kruskal-Wallis H-tests, among others. There is flexibility in the topics depending on student interest!
  </li>
  </p>
</div>

<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading">Autumn 2021</h2>

  <h4> Nick Irons: Introduction to Bayesian Data Analysis</h4>
  <h5> Student:  Xuweiyi (William) Chen </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/xuweiyi.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/xuweiyi.pdf"> Writeup </a>
  </h5>

  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Knowledge of expectations and probability distributions at the level of STAT 340-341 and some knowledge of R.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Bayesian statistics is a method of modeling data that synthesizes our prior beliefs about the data with the information contained in the sample to estimate model parameters. Rather than a single point estimate of a parameter, the output of a Bayesian model is a "posterior" distribution which captures the uncertainty in our inferences. Bayesian methods are at the heart of many modern data science and machine learning techniques. In this introduction to Bayesian statistics we will cover conditional distributions, Bayes' theorem, basics of Bayesian modeling, conjugate priors, MCMC sampling, and application to real dataset(s) of interest to the student in R. If time permits, possible further directions include hypothesis testing, linear regression, hierarchical models, and the EM algorithm for missing data. The goal of this project is to come away with an understanding of the basic conceptual and technical aspects of Bayesian inference and to get our hands dirty with real and interesting data. Possible data applications include estimating (potentially waning) COVID vaccine efficacy, estimating COVID prevalence over time in Washington state, or any other dataset of interest to the student.
  </li>
  </p>

  <h4> Alex Ziyu Jiang:   Clustering and music genre classification </h4>
    <h5> Student:  Yitong (Eva) Shan </h5>
     <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/yitong.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/yitong.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: Knowledge of probability at the level of Stat 311 or beyond; Some coding experiences, preferably in Python or R; It will be fantastic if you also happen to like listening to music ;)</i>

  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Have you ever been amazed by the sheer amount of music genres in your Spotify or Apple Music App and would like to know about their differences in a quantitative way? In this project you will learn how to process audio data and use some interesting clustering techniques in machine learning to classify songs into different genres.
  </li>
  </p>

  <h4> David Marcano and Daniel Suen:  Cluster Analysis </h4>
    <h5> Students:  Townson Cocke and Renee Chien </h5>
     <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/renee.pdf"> Renee Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/renee.pdf"> Renee Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: Basic knowledge of R or Python, statistical background equivalent to STAT 311 is recommended
  </i>

  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    In many real-world data applications, from medicine to finance, it is of interest to find groups within the data. Clustering is an unsupervised learning approach for separating data into representative groups. How to find and assess the quality of these discovered clusters is a vast area of modern research. In this project, we will survey several popular clustering techniques and utilize them in simulated and real datasets. In particular, we will explore center-based approaches such as the k-means algorithm, dissimilarity-based approaches such as hierarchical clustering, probability-based approaches such as mixture models, and other techniques based on student interest. We will also look at how to assess a given clustering. The topics covered and their depth will develop based on the interest and statistical/mathematical level of the student. We are happy to take two students if more than one person is interested in this project.
  </li>
  </p>

  <h4> Anna Neufeld: Multiple Testing </h4>
  <h5> Student:  Cathy Qi </h5>
   <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/cathy.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/cathy.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites:
        Stat 311 and some knowledge of R will be helpful, but not required.
      </i>
      </li>
  <li style="padding:0px;margin:0px 20px 0px;">

  In an introductory statistics course, you learn how to obtain a p-value to test a single null hypothesis. These p-values are constructed such that, when the null hypothesis is true, you will make a mistake and reject the null only 5% of the time. In the real world, scientists often wish to test thousands of null hypotheses at once. In this setting, making a mistake on 5% of the hypotheses could lead to a very high number of false discoveries. Multiple testing techniques aim to limit the number of mistakes made over a large set of hypotheses without sacrificing too much power. We will start with a review of hypothesis testing, then discuss the challenges posed by large numbers of hypotheses, and finally learn about modern multiple testing techniques. Towards the end of the quarter, we will apply the techniques we learned to real data.

  </li>
  </p>

  <h4> Michael Pearce: Voting, Ranking, and Preference Modeling
  </h4>
    <h5> Student:  Carolina Sawyer </h5>
     <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/carolina.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/carolina.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
  Stat 311 or equivalent
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Preference data appears in many forms: voters deciding between candidates in an election, movie critics rating new releases, and search engines ranking web pages, to name a few! However, modeling preferences in a statistical manner can be challenging for a variety of reasons, such as computational difficulties in working with discrete and high-dimensional data. In this project, we will study a variety of models used for preference data, which includes both ranking and scoring models. Understanding challenges and uncertainty in aggregating preferences will be a key focus. Together, we will also carry out an applied project on preference data based on the student's interests.
  </li>
  </p>

  <h4> Seth Temple: Statistical Genetics I, Pedigrees and Relatedness </h4>
    <h5> Student:  Michael Yung </h5>
     <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/michael.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/michael.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        STAT 311; some programming experience preferred
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
  We will explore statistical theory and methodology as it applies to the study of (human) heredity. The overarching theme of the readings are (1) to compute measures of relatedness (kinship and inbreeding) and conditional trait (disease) risk based on known family trees and (2) to estimate relatedness given dense SNP or entire genome sequence data. Readings will follow UW emeritus professor Elizabeth Thompson’s monograph “Statistical Inference from Genetic on Pedigrees”. We will cover conditional probabilities, likelihood models, Hardy-Weinberg equilibrium, the expectation-maximization algorithm to infer allele frequencies for the ABO blood group, Wright’s path counting formula, and identity by descent. During meetings we will work through practice exercises; for 1 or 2 meetings we will go through brief hands-on labs using current research software. The final project may involve estimating familial relationships among individuals in the 1000 Genomes database and comparing outputs among various statistical software.
  </li>
  </p>

  <h4> Vydhourie R.T. Thiyageswaran: Graph Clustering </h4>
    <h5> Student:  Dawei Wang </h5>
     <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/dawei.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/dawei.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Introductory Linear Algebra (and interest in basic introductory graph theory would be helpful)
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
  We will explore clustering methods in graphs. We will focus on k-means clustering, and spectral clustering. Additionally, we would spend some time looking at applications, by thinking about studies explored in statistical blog entries, for example, in FiveThirtyEight. If there’s interest, we can look into replicating and extending on some of the ideas in these studies.
  </li>
  </p>

  <h4> Steven Wilkins-Reeves: An Introduction to Causal Inference and Sensitivity Analysis
   </h4>
   <h5> Student:  Hadi Nazirool Bin Yusri </h5>
    <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/hadi.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/hadi.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        Stat 311 (would be useful to have familiarity with linear regression)
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
  Randomized controlled trials are often called the “gold standard” for assessing the effect of a treatment on an outcome.  However, for many scientific questions, a randomized controlled trial may be either unethical (i.e. you can’t force someone to smoke to figure out whether it causes cancer), or down right impossible (i.e. you can’t assign someone a higher birth weight). Techniques from causal inference can help us to estimate these treatment effect using only observational data, and some identifying assumptions.  Sensitivity analysis can tell us how robust our conclusions are to violations of those assumptions.  In this project, you will read parts of Causal Inference: A Primer by Judea Pearl, as well as some papers on the topic.  A final project may involve analyzing an observational dataset of your choice applying causal inference and sensitivity analysis techniques.
  </li>
  </p>

  <h4> Kenny Zhang: Basics of Causal Inference</h4>
   <h5> Student: Qiguang Yan </h5>
    <h5> <a href = "https://spa-drp.github.io/writeups/aut2021/slides/qiguang.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/aut2021/writeups/qiguang.pdf"> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        STAT 311 level statistics, some familarity with regression is a plus.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
  "Correlation is not causation" used to prevent statisticians from answering questions like "Will smoking cause Lung cancer?". However, with the tool of causal inference and the emergence of big data, we are able to answer some of the questions on a firm scientific basis. We can use causal inference to look at a variety of topics including vaccination, genes etc.
  </li>
  </p>
</div>



<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading">Spring 2021</h2>

  <h4> Peter Gao: Ethics of Algorithmic Decision Making </h4>
  <h5> Student:  Kevin Hoang </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/spring2021/kevin_slides.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2021/kevin_writeup.pdf""> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        None
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    In this project, we'll discuss ethical issues arising from the use of algorithms in decision making, in fields like medicine, policing, and housing. We'll talk about issues ranging from algorithmic bias and disparate impact to data privacy. Finally, we'll introduce statistical definitions of fairness and talk about their benefits and shortcomings. If there's interest, we can work on simulations/data analysis to evaluate statistical definitions of fairness.
  </li>
  </p>

  <h4> Alex Ziyu Jiang: Sampling methods, Markov Chain Monte Carlo and Cryptography </h4>
  <h5> Student: Kathleen Cayha </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/spring2021/kathleen_slides.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2021/kathleen_writeup.pdf""> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Basic knowledge of probability is recommended (STAT 311 level). Some prior coding experience with R would be great but not necessary
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
In this project we learn how to decipher coded messages with the widely-used Markov Chain Monte Carlo method. We will first go through the basics of Markov Chain model after a quick probability warm-up. After that we will learn how to generate samples from a known distribution using a wide range of techniques. Finally, we will apply our tools to a dataset consisting of coded messages and we will see how the 'messy' code will gradually iterate into complete sentences using what we have learned.  </li>
  </p>

  <h4> Alan Min and Anupreet Porwal: Expectations and Sampling methods </h4>
  <h5> Students: Kai Gong and Aubrey Yan </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/spring2021/kai_slides.pdf"> Kai Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2021/kai_writeup.pdf"> Kai Writeup </a>
    <h5> <a href = "https://spa-drp.github.io/writeups/spring2021/aubrey_slides.pdf"> Aubrey Slides </a>,
      <a href = "https://spa-drp.github.io/writeups/spring2021/aubrey_writeup.pdf""> Aubrey Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        STAT 340-341 and some knowledge of R ; Basics of expectations and probability distributions.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Expectation of a random variable or functions of random variables can be difficult to compute analytically when the probability distribution of those variables are not standard well known distributions. One way to approximate expectations is by “intelligently” drawing samples from the probability distributions. In this project, we will cover several sampling and Monte Carlo methods to draw samples from “difficult distributions” and use these samples to approximate expectations. Particularly, we will look at transformation based sampling, importance sampling, rejection sampling and their popular variants. Finally, we will compare performances of these sampling methods and apply the methodology to a dataset of interest to the student in a Bayesian analysis. We are happy to take two students if more than one person is interested in this project.
  </li>
  </p>


      <h4> Anna Neufeld: Infectious disease modeling </h4>
        <h5> Student: Kayla Kenyon </h5>
      <h5> <a href = "https://spa-drp.github.io/writeups/spring2021/kayla_slides.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2021/kayla_writeup.pdf""> Writeup </a> </h5>
      <p class="content" style="padding:0px;margin:0px 20px 0px;">
        <p class="content" style="padding:0px;margin:0px 20px 0px;">
            <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
              Some comfort in R; experience with calculus and differential equations will be useful but not required.
         </li>
            <li style="padding:0px;margin:0px 20px 0px;"> We will start by reading introductory material on SIR compartmental models for disease modeling, and will work to implement these models in R. These are deterministic differential equation models whose output depends on knowledge of various input parameters. After becoming comfortable with the models, we will discuss how statisticians estimate the parameters of these models using current outbreak data in the face of uncertainty, and how the models are then used for predictions and forecasting. The project will evolve based on the interest and statistical level of the student, but could potentially culminate in an applied COVID-19 modeling project.
        </li>
        </p>


      <h4> Michael Pearce: Nonlinear Regression </h4>
              <h5> Student: Muhammad Anas </h5>
              <h5> <a href = "https://spa-drp.github.io/writeups/spring2021/kevin_slides.pdf"> Slides </a>,
                <a href = "https://spa-drp.github.io/writeups/spring2021/kevin_writeup.pdf""> Writeup </a>
              </h5>
      <p class="content" style="padding:0px;margin:0px 20px 0px;">
          <li style="padding:0px;margin:0px 20px 0px;"> <i>
            Prerequisites: </i>
            A basic knowledge of linear regression and some experience in R
      </li>
      <li style="padding:0px;margin:0px 20px 0px;">
      Simple linear regression models can be easy to implement and interpret, but they don't always fit data well! For this project, we'll explore regression methods that relax the assumption of linearity. These might include (based on the interest and/or experience level of the student) polynomial regression, step functions, regression splines, smoothing splines, multivariate adaptive regression splines, and generalized additive models. Hopefully, we'll even see how to validate such models using cross-validation! We will mostly use James et al.'s "An Introduction to Statistical Learning" Chapter 7.
      </li>
      </p>

      <h4> Taylor Okonek: Disease Mapping </h4>
      <h5> Student: Wuwei Zhang </h5>
 <h5> <a href = "https://spa-drp.github.io/writeups/spring2021/wuwei_slides.pdf"> Slides </a>,
   <a href = "https://spa-drp.github.io/writeups/spring2021/wuwei_writeup.pdf""> Writeup </a>
 </h5>

      <p class="content" style="padding:0px;margin:0px 20px 0px;">
          <li style="padding:0px;margin:0px 20px 0px;"> <i>
            Prerequisites: </i>
            STAT 340; Interest in public health applications; Familiarity with R
      </li>
      <li style="padding:0px;margin:0px 20px 0px;">
      Disease mapping is an important tool for visualizing spatial data on the prevalence and/or incidence of various diseases. In this project, we’ll discuss different types of spatial data, and explore visualization techniques and their usefulness in conveying relevant information. In particular, we’ll discuss ways to visualize uncertainty in disease mapping, how estimates underlying a disease map inform public health policy, issues with data sparsity and spatial aggregation, and how to obtain the estimates that underlie such maps. We’ll learn about Bayesian hierarchical models and, time permitting, spatial random effect terms. Throughout, we’ll explore concepts using real data from various diseases that are of student interest.
      </li>
      </p>

      <h4> Sarah Teichman: Ethics of Algorithmic Decision Making </h4>
    <h5> Student:  Liwen Peng </h5>
      <h5> <a href = "https://spa-drp.github.io/writeups/spring2021/liwen_slides.pdf"> Slides </a>,
        <a href = "https://spa-drp.github.io/writeups/spring2021/liwen_writeup.pdf""> Writeup </a>
      </h5>
      <p class="content" style="padding:0px;margin:0px 20px 0px;">
          <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
            None
      </li>
      <li style="padding:0px;margin:0px 20px 0px;">
        In this project, we'll discuss ethical issues arising from the use of algorithms in decision making, in fields like medicine, policing, and housing. We'll talk about issues ranging from algorithmic bias and disparate impact to data privacy. Finally, we'll introduce statistical definitions of fairness and talk about their benefits and shortcomings. If there's interest, we can work on simulations/data analysis to evaluate statistical definitions of fairness.
      </li>
      </p>

  <h4> Apara Venkat: Networks and Choice Modeling </h4>
  <h5> Student: Andrey Risukhin </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/spring2021/andrey_slides.pdf"> Slides </a>,
  <a href = "https://spa-drp.github.io/writeups/spring2021/andrey_writeup.pdf""> Writeup </a>
</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Calculus (MATH 126) and exposure to probability theory (STAT 340). Linear Algebra (MATH 308) suggested, but not necessary.
      A general interest and curiosity about math and the world. </li>
      <li style="padding:0px;margin:0px 20px 0px;">
        Imagine a grocery store that presents its customers with a multitude of cereal options. A rational customer would want to maximize their utility. How do you define the "utility" of an item? How do you model the decisions of a customer when there are random effects?
        If we have data from decisions made by customers, can we identify the
        utility of various cereals? Discrete choice models attempt to answer these questions.
        In the language of networks, this problem is closely related to ranking.
        How does Google rank the webpages? How do we rank players in sports tournaments?
        Recent developments have been unifying these fields.

  In this project, we will wrestle with these questions. First, we will learn about discrete choice models.
  Then, we will learn about ranking in networks. Finally we will attempt to reconcile the two.
  Time permitting, we will also run simulations and look at datasets along the way.
   </li>
  </p>
  </div>

<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading">Winter 2021</h2>

  <h4> Peter Gao: Survey of Data Journalism </h4>
  <h5> Student: Rohini Mettu </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/win2021/rohini_slides.pdf"> Slides </a>,
    <a href = "https://spa-drp.github.io/writeups/win2021/rohini_writeup.pdf""> Writeup </a>
  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
        None
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
In this project, we'll take a look at recent uses of data and statistics in journalism and discuss their effectiveness in applying statistical methods and communicating results to their readers. If desired, we can focus on a specific area of application (climate change, economics, sports, epidemiology). If there is interest, we can look into replicating and extending a particular example.
  </li>
  </p>


  <h4> Richard Guo: Making probability rigorous </h4>
    <h5> Student: Mark Lamin </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
    Probability theory at the level of MATH/STAT 394 and 395
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
Having sat through the introductory probability course, likely you have heard things like "Lebesgue measure", "sigma algebra", "almost sure convergence" and even "martingale" being mentioned. Do you wonder what they are and why they matter? This is a reading program that will introduce these notions and make the probability you learned *rigorous*. We will read together the acclaimed monograph "Probability with Martingales" by David Williams. Rigorous treatment of probability and measure theory will prepare you for more advanced topics, such as stochastic processes, learning theory and theoretical statistics.

  </li>
  </p>


  <h4> Bryan Martin: Statistical Learning with Sparsity </h4>
    <h5> Student: Jerry Su </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
    Familiarity with regression, up to a STAT 311 level
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Many modern applications benefit from the principle of less is more. Whether due to practical computation concerns from big data, overfitting concerns from too many parameters, or estimability concerns from a small sample size, statistical models often require sparsity. Sparsity can improve our predictions, help make the patterns we observe in our data more reproducible, and give our model parameters desirable properties.

    Often, sparsity is imposed through penalization, where we include a term in our model to enforce that some parameters are set equal to zero. We will learn about some of the statistical theory underlying how penalization works, and how it impacts our model output, both mathematically and computationally. We will also learn about and compare different sparsity schemes, such as lasso, group lasso, elastic net, and more. We will focus on understanding the different settings in which we might be interested in different forms of sparsity and apply these tools to real data.
  </li>
  </p>


  <h4> Eric Morenz and Yiqun Chen: See what's not there </h4>
    <h5> Student: Suh Young Choi </h5>
    <h5> <a href = "https://spa-drp.github.io/writeups/win2021/suh_slides.pdf"> Slides </a>,
      <a href = "https://spa-drp.github.io/writeups/win2021/suh_writeup.pdf""> Writeup </a>
    </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i>
        Prerequisites: </i>
        Experience with linear regression, probability, or data manipulation will allow a deep dive into the content.
        It is not a requirement for students who are interested in the subject.
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    In this project, we will take a look at the concept of identification in the context of missing data (and causal inference, if time permits or there is interest!!).
    While no glamorous artificial intelligence buzzwords are involved in the project per se,
    remember that your model is just as good as your data (and as we will see by the end of the
     quarter, as good as your identification assumptions!). We will be drawing from various sources
      (e.g., Chapter 6 in Foundations of Agonistic Statistics) in the hope of
      flexible schedule/materials given your background and interest. We will consider a
      few empirical problems as well, from TidyTuesday data sets to political polls.
  </li>
  </p>

  <h4> Taylor Okonek:  Topics in Biostatistics </h4>
      <h5> Student: Anna Elias-Warren </h5>
      <h5> <a href = "https://spa-drp.github.io/writeups/win2021/anna_slides.pdf"> Slides </a>,
        <a href = "https://spa-drp.github.io/writeups/win2021/anna_writeup.pdf""> Writeup </a>
      </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i>
        Prerequisites: </i>
         Introductory statistics a plus but not required, interest in public health applications
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
     In this project, we’ll first broadly discuss some of the main pillars of the field of biostatistics, and then focus on a more specific topic for the remainder of the quarter. The main pillars we'll discuss include design of clinical trials, survival analysis, and infectious disease modeling. The focused part of this project can be greatly driven by student interest. Possible directions include: doing a deep-dive into the design of COVID-19 vaccine trials; reading articles about and discussing implications of communicating public health analyses to the public; gaining a broad understanding of how infectious disease models have influenced policy throughout the world; reading about ethical issues in global health studies; and more!
  </li>
  </p>

  <h4> Michael Pearce: Nonlinear Regression </h4>
      <h5> Student: Alejandro Gonzalez </h5>
      <h5> <a href = "https://spa-drp.github.io/writeups/win2021/alejandro_slides.pdf"> Slides </a>,
        <a href = "https://spa-drp.github.io/writeups/win2021/alejandro_writeup.pdf""> Writeup </a>
      </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i>
        Prerequisites: </i>
        A basic knowledge of linear regression and some experience in R
  </li>
  <li style="padding:0px;margin:0px 20px 0px;">
  Simple linear regression models can be easy to implement and interpret, but they don't always fit data well! For this project, we'll explore regression methods that relax the assumption of linearity. These might include (based on the interest and/or experience level of the student) polynomial regression, step functions, regression splines, smoothing splines, multivariate adaptive regression splines, and generalized additive models. Hopefully, we'll even see how to validate such models using cross-validation! We will mostly use James et al.'s "An Introduction to Statistical Learning" Chapter 7.
  </li>
  </p>


<h4> Sarah Teichman: Multivariate Data Analysis  </h4>
<h5> Student: Lindsey Gao </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/win2021/lindsey_slides.pdf"> Slides </a>,
  <a href = "https://spa-drp.github.io/writeups/win2021/lindsey_writeup.pdf""> Writeup </a>
</h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  <li style="padding:0px;margin:0px 20px 0px;"> <i>
    Prerequisites: </i>
    Stat 311, and linear algebra would be helpful but not necessary
</li>
<li style="padding:0px;margin:0px 20px 0px;">
Almost all datasets collected across disciplines are multivariate, which means that multiple variables are measured. Recent technological advances have let researchers collect datasets with hundreds or thousands of variables. Methods from introductory statistics can be used to measure the relationship between a small subset of variables, but new methods are required to consider all of the data simultaneously. Multivariate data analysis is a set of tools to visualize, explore, and make inference about this type of data. In this project, we will use the textbook "An Introduction to Applied Multivariate Analysis with R" to learn about several methods for multivariate data analysis, including principal components analysis, multidimensional scaling, and clustering. We will choose a dataset of interest at the beginning and apply each of our methods to this dataset, leading to a final data analysis and comparison across methods.
</li>
</p>

<h4> Seth Temple: Statistical Genetics and Identity by Descent  </h4>
<h5> Student: Selma Chihab </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/win2021/selma_slides.pdf"> Slides </a>,
  <a href = "https://spa-drp.github.io/writeups/win2021/selma_writeup.pdf""> Writeup </a>
</h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  <li style="padding:0px;margin:0px 20px 0px;"> <i>
    Prerequisites: </i>
  STAT 311; some programming experience preferred
</li>
<li style="padding:0px;margin:0px 20px 0px;">
We will explore statistical theory and methodology as it applies to the study of (human) heredity. The overarching theme of the readings are (1) to compute measures of relatedness (kinship and inbreeding) and conditional trait (disease) risk based on known family trees and (2) to estimate relatedness given dense SNP or entire genome sequence data. Readings will follow UW emeritus professor Elizabeth Thompson’s monograph “Statistical Inference from Genetic on Pedigrees”. We will cover conditional probabilities, likelihood models, Hardy-Weinberg equilibrium, the expectation-maximization algorithm to infer allele frequencies for the ABO blood group, Wright’s path counting formula, and identity by descent. During meetings we will work through practice exercises; for 1 or 2 meetings we will go through brief hands-on labs using current research software
</li>
</p>

<h4> Apara Venkat: Networks and Choice Modeling </h4>
<h5> Student: Xuling Yang </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/win2021/xuling_slides.pdf"> Slides </a>,
  <a href = "https://spa-drp.github.io/writeups/win2021/xuling_writeup.pdf""> Writeup </a>
</h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
  Calculus (MATH 126) and exposure to probability theory (STAT 340). Linear Algebra (MATH 308) suggested, but not necessary.
  A general interest and curiosity about math and the world. </li>
  <li style="padding:0px;margin:0px 20px 0px;">
    Imagine a grocery store that presents its customers with a multitude of cereal options. A rational customer would want to maximize their utility. How do you define the "utility" of an item? How do you model the decisions of a customer when there are random effects?
    If we have data from decisions made by customers, can we identify the
    utility of various cereals? Discrete choice models attempt to answer these questions.
    In the language of networks, this problem is closely related to ranking.
    How does Google rank the webpages? How do we rank players in sports tournaments?
    Recent developments have been unifying these fields.

In this project, we will wrestle with these questions. First, we will learn about discrete choice models.
Then, we will learn about ranking in networks. Finally we will attempt to reconcile the two.
Time permitting, we will also run simulations and look at datasets along the way.

   </li>
</p>

<h4> Jerry Wei: Topological Data Analysis </h4>
<h5> Student: Joia Zhang </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/win2021/joia_slides.pdf"> Slides </a>,
  <a href = "https://spa-drp.github.io/writeups/win2021/joia_writeup.pdf""> Writeup </a>
</h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites:
Exposure to probability theory and linear algebra
</i>
   </li>
  <li style="padding:0px;margin:0px 20px 0px;">
  Topological Data Analysis (TDA) broadly is about data analysis methods that find structure in data. This includes a lot of topics, and we will focus on clustering and nonlinear dimension reduction. We will study some textbook chapters and some classical papers.
  We may also go into mode estimation and manifold estimation if interested.
   </li>
</p>

<h4> Kenny Zhang: Deep Learning for Computer Vision </h4>
<h5> Student: Angela Zhao</h5>
<h5> <a href = "https://spa-drp.github.io/writeups/win2021/angela_slides.pdf"> Slides </a>,
  <a href = "https://spa-drp.github.io/wrtiteups/win2021/angela_writeup.pdf""> Writeup </a>
</h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
  <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
    Proficiency in a programming language (preferably python). Some exposure in basic probability rules and computer science would be helpful.
</li>
<li style="padding:0px;margin:0px 20px 0px;">
Image data is prevalent in our lives and modern deep learning provides a powerful
tool to deal with image data. We will start with logistic regression and study what is a
neural network. Then we will move on to convolutional neural network and some coding exercises.
If time allowed, we can delve more into the state-of-the-art Generative Adversarial Networks
(GAN) and more complicated tasks like segmentation.
</li>
</p>

</div>



<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading">Autumn 2020</h2>

<h4> Peter Gao: Statistics for Data Journalism: Election Forecasting </h4>
  <h5> Student: Andy Qin </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/aut2020/andy-slides.pdf"> Slides </a> </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Experience with introductory stats (at the level of any of the intro classes)
      would help.
</li>
<li style="padding:0px;margin:0px 20px 0px;"> In this project, we'll take a look at how leading
newspapers and researchers conduct polls,
forecast elections, and calculate polling averages. If there is interest, we can work on reverse
engineering some of the methods used by publications such as FiveThirtyEight, RealClearPolitics, and the Upshot.
Finally, we'll consider the ethics of forecasting elections and using statistics in general to study our election process.
</li>
</p>

<h4> Zhaoqi Li: Statistical Illusions </h4>
  <h5> Student: Yeji Sohn </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/aut2020/yeji-slides.pdf"> Slides </a> </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i>
      Prerequisites: </i> Motivation to think about interesting problems and readiness for the brain to be teased. Some mathematical maturity would be beneficial.
</li>
<li style="padding:0px;margin:0px 20px 0px;">
  Do you know that there is a “statistically significant” relationship between your salary and if you pee at night? Do you know that you will always wait longer than others at a bus stop? Do you know that a lot of the statistical concepts you learned in class actually don’t make sense? In this quarter-long study, we will dive into some common misconceptions about statistics and the questions of how to interpret statistics. We will touch on a wide range of statistical topics from a paradoxical view and learn the intuition behind them.
  No prior knowledge of statistics is required but motivation is encouraged.
</li>
</p>

<h4>Shane Lubold: Random Network Models</h4>
  <h5> Student: Peter Liu </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/aut2020/peter-slides.pdf"> Slides </a> </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Intro statistics and some programming experience (R or Python). </li>
    <li style="padding:0px;margin:0px 20px 0px;">
      Network data, which consists of edges or relationships between nodes, is an important type of data. Many statistical models have been proposed to understand and model this type of data. Some are simple models which assume that all actors form connections with the same probability, while others are more complicated and use node-specific characteristics to determine the probability of an edge. In this project we will first review common network models (such as the Erdos-Renyi model, stochastic block model, and latent space model) and discuss why they might be useful in practice. We will then fit these models to data sets from the Stanford Network Analysis Project and discuss why some models fit better than others. The goal of the project is to understand how network data can arise in the real world and how network properties determine which models are reasonable. If we have time, we can also look at dynamic networks (networks that change over time) and see if we can model them using any of the models discussed above.

     </li>
</p>

<h4> Bryan Martin: Ethics in Data Science and Statistics </h4>
<h5> Student: Jinghua Sun </h5>
<h5> <a href = "https://spa-drp.github.io/writeups/aut2020/jinghua-slides.pdf"> Slides </a> </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites:
    None </i>
     </li>
    <li style="padding:0px;margin:0px 20px 0px;">
      In this project, we will discuss ethical questions and issues that arise in the field of statistics and data science. We will read case studies and work together to develop a lesson that can be taught to introductory statistics students as part of an undergraduate curriculum. By the end of this project, I hope to have material that I will use in my own courses! Topics will be driven by the student's particular interest, but possible topics will include: the history of statistics and eugenics, race and gender in data science, algorithmic fairness, reproducibility and open science, data transparency, privacy, and human subjects data.
     </li>
</p>



<h4> Ronak Mehta: The Magical Properties of the SVD </h4>
  <h5> Student: Claire Gao </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i>
      Prerequisites: </i>
      Linear Algebra (Math 308 or equivalent). Some statistical background, preferably at
    the level of 340.
</li>
<li style="padding:0px;margin:0px 20px 0px;">
  The singular value decomposition (SVD) of a matrix has wide relevance in virtually all areas of applied mathematics. This project will consist of three parts:
  1) a theory section containing proofs of intriguing properties about the SVD and derivations of three problems of wide importance in statistics and machine learning: principle components analysis (PCA), partial least squares (PLS), and canonical correlations analysis (CCA), all of whose solutions depend heavily on the SVD.
  2) a simulation section demonstrating the bias-variance tradeoff of using on method over another for various regression/classification tasks.
  3) a real data section in which the student interprets the features learned by these methods on a dataset of their choice.
  This project is ideal for intermediate statistics students who want to make their linear algebra skills airtight and have a strong mathematical foundation for future success in machine learning.
</li>
</p>

<h4>Anna Neufeld:  Infectious Disease Modeling  </h4>
  <h5> Student: Harper Zhu </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/aut2020/harper-slides.pdf"> Slides </a>,
    <a href = "https://harperzhu.shinyapps.io/DiseaseSimulation/"> Shiny App </a>
  </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      Some comfort in R; experience with calculus and differential equations will be useful but not required.
 </li>
    <li style="padding:0px;margin:0px 20px 0px;"> We will start by reading introductory material on SIR compartmental models for disease modeling, and will work to implement these models in R. These are deterministic differential equation models whose output depends on knowledge of various input parameters. After becoming comfortable with the models, we will discuss how statisticians estimate the parameters of these models using current outbreak data in the face of uncertainty, and how the models are then used for predictions and forecasting. The project will evolve based on the interest and statistical level of the student, but could potentially culminate in an applied COVID-19 modeling project.
</li>
</p>

<h4> Michael Pearce: History and Practice of Data Communication </h4>
  <h5> Student: Ziyi Li </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/aut2020/ziyi-writeup.pdf"> Writeup </a> </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      None; some experience with R or Python may be helpful but is not required.
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
      In this course, we'll learn about the development of data communication techniques and their modern use. We'll begin by studying how people have visualized patterns in data over time, and consider how those methods reflected the computational resources available in each era. Then, we'll shift our attention to modern issues in data communication, drawing examples from the COVID-19 pandemic and 2020 US presidential election: How do practitioners effectively show complex relationships or model uncertainty? How do people mislead readers through text and figures (intentionally or otherwise)? What common pitfalls exist, and how can we avoid them? We'll finish with a data communication project based on the student's interests.
</li>
</p>

<h4>Subodh Selukar: Introduction to Survival Analysis</h4>
  <h5> Student: Howard Baek </h5>
  <h5>
  <a href = "https://spa-drp.github.io/writeups/aut2020/howard-writeup.pdf"> Writeup </a>,
<a href = "https://howiebaek-2.shinyapps.io/mixture-cure-model-sim/"> Shiny App </a>
</h5>

<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
Familiarity with R; familiarity with survival analysis
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
    In many applications, researchers are interested in the time it
    takes for an outcome of interest to occur: for example, time to death by
    any cause ("overall survival") is the gold standard outcome for studies in many
    biomedical fields. Among other characteristics, these data exhibit a special kind of
    missingness termed "censoring," which requires the use of different statistical methods
    than other data types. In this project, the student will learn about the characteristics of
    time-to-event (or "survival") data and basic methods for approaching these data.
</li>
</p>

<h4> Sarah Teichman: Phylogenetic Trees </h4>
  <h5> Student: Lexi Xia </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/aut2020/lexi-writeup.pdf"> Writeup </a> </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
      An intro stats class. Some R experience is useful but not required.
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
      In this project, we will learn about the application of statistics to evolutionary biology through working with phylogenetic trees. In evolutionary biology, a diagram in the form of a tree is often used to represent the diversification of species over time. In this project, we'll read chapters from the book \emph{Tree Thinking} and choose a dataset to investigate deeply in R in order to understand phylogenies: what they are, how they are used, and how we can use statistics to construct them and test hypotheses about evolution.
      </li>
</p>


<h4> Seth Temple: Statistical Genetics and Identity by Descent </h4>
  <h5> Student: Rachel Ferina </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/aut2020/rachel-slides.pdf"> Slides </a>  <a href = "https://spa-drp.github.io/writeups/aut2020/rachel-writeup.pdf"> Writeup </a> </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i>
None; keen interest in the biological sciences
 </li>
    <li style="padding:0px;margin:0px 20px 0px;">
We will explore many classical ways in which statistics has been employed to study heredity in humans and other organisms. For example, we will introduce the expectation-maximization algorithm to infer allele frequencies for ABO blood types and discuss Jacquard’s 9 condensed states of identity by descent. This tutorial will be very practical as we will draw many family trees to compute kinship and inbreeding coefficients. We will use UW emeritus professor Elizabeth Thompson’s monograph "Statistical Inference from Genetic Data on Pedigrees" as reading material. Depending on student interest, we may read more chapters from Thompson’s book, investigate the history of statistical genetics as it relates to the eugenics movement, or code up some computations like the path counting formula.
</li>
</p>
</div>

<div class="col-md-8">
  <h2 style="padding-top: 10px;" class="featurette-heading">Spring 2020</h2>
<p> We ran a limited number of projects due to COVID-19. </p>

<h4> Sheridan Grant: Causal Inference: DAGs and Potential Outcomes </h4>
  <h5> Student: Grace Shen </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/spring2020/grace.pdf"> Slides </a>  </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Familiarity with linear regression and facility with
    Gaussian distributions (preferably multivariate)
</li>
<li style="padding:0px;margin:0px 20px 0px;">
This project will be reading-focused, rather than data analysis.
It's intended for a junior or senior student who is interested in learning about Causal Inference--a
huge topic in graduate-level statistics and stats research--perhaps as a prelude
to applying for PhDs. You'll read classic papers and parts of textbooks on two approaches
to causal inference, potential outcomes & graphs. For the final presentation,
you'll contrast the two approaches as applied to a problem (practical or theoretical) of your choice.
</li>
</p>

  <h4>Shane Lubold: Random Graphs </h4>
  <h5> Student: Gordon An </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Some exposure to probability. Some exposure to, or an interest in, graph theory. </li>
      <li style="padding:0px;margin:0px 20px 0px;"> In this project, we will study random graph theory and how the behavior of these graphs change as the size of the graph grows. We will focus primarily on a simple graph model with a number of interesting properties, the Erdös-Rényi model. In this simple model, we generate a graph on n nodes, where each node connects to any other node with probability p(n), which can depend on the graph size n. We will use theory and simulations to derive key properties of this model, such as the distribution of the degree of a vertex or the number of cliques of any size. We will also explore other exciting properties of this model. For example, if the ratio p*n grows at a certain rate as n gets big, then the graph will, for example, exhibit large cliques with probability 1. The proof of these ideas uses only basic statistical ideas. We will prove the conditions that guarantee this behavior and use simulations to explore how large the graphs must be the see this behavior. This project will expose students to the exciting field of random graphs and will give them a good understanding of how simple statistical tools can answer complex questions. </li>
  </p>

  <h4>Anna Neufeld:  Disease Modeling  </h4>
    <h5> Student: Rachael Ren </h5>
    <h5> <a href = "https://spa-drp.github.io/writeups/spring2020/rachael.pdf"> Writeup </a>,
    <a href = "https://spa-drp.github.io/writeups/spring2020/rachaelslides.pdf"> Slides </a> </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Knowledge of R will be useful!  </li>
      <li style="padding:0px;margin:0px 20px 0px;"> We will start by reading introductory material on SIR compartmental models for disease
        modeling, and will work to implement these models in R. These are deterministic differential equation models
        whose output depends on knowledge of various input parameters. After becoming comfortable with the models,
        we will discuss how statisticians estimate the parameters of these
        models using current outbreak data in the face of uncertainty, and how the models are then used for predictions and forecasting.
        The project will evolve based on the interest of the student and relevant currnt events.
</li>
  </p>

  <h2 style="padding-top: 10px;" class="featurette-heading">Winter 2020</h2>
<h4> Peter Gao: Introduction to Gaussian Processes</h4>
<h5> Student: Hannah Chang </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> None; interest in programming encouraged
</li>
<li style="padding:0px;margin:0px 20px 0px;"> As a concept, the Gaussian distribution, often referred to as the normal distribution or the bell curve, has cemented itself in the public consciousness. But what about its finite dimensional generalization, the multivariate Gaussian? Or its infinite dimensional counterpart, the Gaussian process? This project has two main aims: first, to discuss and explore how Gaussian processes arise in various subfields like machine learning and spatial statistics; and second, to develop notes (or a website) that explain Gaussian processes to a general audience. Of course, the exact focus of this project is flexible, based on the reader's interests/background.
</li>
</p>
  <h4> Kristof Glauninger: Nonparametric Regression </h4>
  <h5> Student: Eli Grosman </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/win2020/eli.pdf"> Writeup </a>  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Familiarity with linear regression and basic probability, comfort with algebra, some calculus
 </li>
<li style="padding:0px;margin:0px 20px 0px;"> Nonparametric statistical methods
  have seen an explosion in popularity as datasets have increased in size and complexity.
  The goal of this project will be to introduce students who are familiar with parametric regression
  models to a nonparametric setting. We will explore some of the basic theory and applications of these models,
  as well as an interesting case where we can achieve parametric convergence rates in a nonparametric setting.
</li>
  </p>
  <!--
  <h4>Zhaoqi Li: Statistical Illusions</h4>
  <h5> (not run)</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites</i>  Motivation to think about interesting problems and readiness for the brain to be teased.  </li>
         <li style="padding:0px;margin:0px 20px 0px;">Do you know that there is a “statistically significant” relationship between your salary and if you pee at night?
            Do you know that you will always wait longer than others at a bus stop?
             Do you know that a lot of the statistical concepts you learned in class actually don’t make sense?
             In this quarter-long study, we will dive into some common misconceptions about statistics and the questions
             of how to interpret statistics.
             We will touch on a wide range of statistical topics from a paradoxical view
             and learn the intuition behind them. No prior knowledge of statistics is required but
             motivation is encouraged. </li>
  </p>
  -->
  <h4>Zhaoqi Li: Statistical Machine Learning and Data Analysis</h4>
    <h5> Student: Zhijun Peng </h5>
    <h5> <a href = "https://spa-drp.github.io/writeups/win2020/peng.pdf"> Writeup </a>  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites</i> Knowledge of probability theory and Maximum Likelihood Estimation at the level of Stat 340 is preferred;
        some familiarity of basic programming is preferred;
         an enthusiasm of reading and experimenting is encouraged.  </li>
         <li style="padding:0px;margin:0px 20px 0px;"> We will discuss the relationship between statistics and machine learning, one of the most popular fields in the world,
           and how statistical techniques could be used in the machine learning framework.
            Topics may include classifiers (e.g., Decision Tree, Naive Bayes),
             training (what is training and the relation to likelihood inference), etc.
           The design could range from experimental to theoretical,
           depending on the background of the student. </li>
  </p>
  <!--
  <h4>Shane Lubold: Applications of Central Limit Theorems </h4>
  <h5> Not run </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Some exposure to linear algebra, the central limit theorem, and coding (such as R, MATLAB, or Python). </li>
      <li style="padding:0px;margin:0px 20px 0px;"> In this project, we will study central limit theorems (CLTs) and their applications in convex geometry and random matrix theory. CLTs are a common tool to understand the behavior of sample means as the sample size gets large. We will first study general conditions on the variables that guarantee a Gaussian limit and will explore how big the sample size must be until our sample averages appear normal. We will then relax these assumptions and discover what the limit becomes (if it exists!) under less restrictive conditions on the random variables. Finally, we will use simulations and theory to explore two exciting applications of CLTs: random matrix theory and convex geometry. First, we will show that the eigenvalues of many types of random matrices satisfy a central limit theorem as the size of the matrix grows. Finally, we will show that the area of convex hulls generated by points drawn from a Gaussian distribution satisfies a central limit theorem! This project will give students an understanding of when and why CLTs exist and how they can be used to answer exciting questions in applied fields. </li>
  </p>
  -->
  <h4>Shane Lubold: Random Graphs </h4>
    <h5> Student: Tahmin Talukder</h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Some exposure to probability. Some exposure to, or an interest in, graph theory. </li>
      <li style="padding:0px;margin:0px 20px 0px;"> In this project, we will study random graph theory and how the behavior of these graphs change as the size of the graph grows. We will focus primarily on a simple graph model with a number of interesting properties, the Erdös-Rényi model. In this simple model, we generate a graph on n nodes, where each node connects to any other node with probability p(n), which can depend on the graph size n. We will use theory and simulations to derive key properties of this model, such as the distribution of the degree of a vertex or the number of cliques of any size. We will also explore other exciting properties of this model. For example, if the ratio p*n grows at a certain rate as n gets big, then the graph will, for example, exhibit large cliques with probability 1. The proof of these ideas uses only basic statistical ideas. We will prove the conditions that guarantee this behavior and use simulations to explore how large the graphs must be the see this behavior. This project will expose students to the exciting field of random graphs and will give them a good understanding of how simple statistical tools can answer complex questions. </li>
  </p>
  <h4>Bryan Martin: R Package Development </h4>
    <h5> Student: Thomas Serrano </h5>
    <h5> <a href = "https://spa-drp.github.io/writeups/win2020/thomas.pdf"> Writeup </a>  </h5>
  <p class="content" style="padding:0px;margin:0px 20px 0px;">
      <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Familiarity with R </li>
      <li style="padding:0px;margin:0px 20px 0px;">  Reproducible statistical analysis depends on good software and coding practices. In this project, we will learn how to go from users of R packages to developers of R packages. We will also practice and implement general software developer skills, including documentation, version control, and unit testing. We will learn how to make our code robust, efficient, and user-friendly. Ideally, you will start with an idea of something you are interested in implementing as an R package, whether it be a statistical model, data analysis application, or anything else, though this is not required! </li>
  </p>
<h4>Anna Neufeld: Statistical Natural Language Processing </h4>
  <h5> Student: Christina Nick </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Proficiency in a programming language. Knowledge of basic
    probability rules at the level of Stat 311.  </li>
    <li style="padding:0px;margin:0px 20px 0px;"> In most statistics classes, the data you work with are numbers. Text documents
      such as books, articles, and speeches provide massive sources of data that can not be analyzed using the tools from your introductory statistics
      courses. We will explore the field of statistical natural language processing and discuss classification and clustering techniques for text data.
      Applications of such techniques include translation, information retrieval, fake news detection, and sentiment analysis.
      After reviewing the literature to get a sense of the general techniques in NLP, we will select a particular
      text dataset and research question and work on an applied project.
 </li>
</p>
<h4> Michael Pearce: Nonlinear Regression </h4>
  <h5> Student: Oliver Bejar Tjalve </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/win2020/oliver.pdf"> Writeup </a>  </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> A basic knowledge of linear regression and some experience in R</li>
    <li style="padding:0px;margin:0px 20px 0px;"> Simple linear regression models can be easy to implement and interpret,
       but they don't always fit data well!
       For this project, we'll explore regression methods that relax the assumption of linearity.
        These might include (based on the interest and/or experience level of the student)
        polynomial regression, step functions, regression splines, smoothing splines,
         multivariate adaptive regression splines, and generalized additive models.
         Hopefully, we'll even see how to validate such models using cross-validation!
         We will mostly use James et al.'s "An Introduction to Statistical Learning" Chapter 7.
    </li>
</p>
<h4>Anupreet Porwal: Bayesian Linear regression and applications </h4>
  <h5> Student: Yuchen Sun </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/win2020/yuchen.pdf"> Writeup </a>  </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i>Prerequisites: </i> Basic knowledge of probability distributions at the level of
      Stat 394 or Stat 340. Knowledge of Linear Algebra is essential for this project. Familiarity with a programming language may be helpful.</li>
      <li style="padding:0px;margin:0px 20px 0px;"> Often when we fit models to practical applications, we have some prior understanding of the context of the problem/field which could potentially be useful to tune our model along with the data. For example, if you are trying to model the reply times of emails from dept. chair to professors, information about the designation of professors (full-time/assistant) can be helpful information.
Bayesian statistics provides a formal way to incorporate our prior beliefs and information into the model and is particularly useful as it accurately helps to quantify the uncertainty in our inferences. In this project, we wish to discuss basics of Bayes theorem, Bayesian version of Linear regression and if time permits, we will learn about probabilistic matrix factorization (Recommendation systems) and apply these techniques to an interesting problem.</li>
</p>

<h4>Sarah Teichman: Networks </h4>
  <h5> Student: Josiah Thulin </h5>
  <h5> <a href = "https://spa-drp.github.io/writeups/win2020/josiah.pdf"> Writeup </a>  </h5>
<p class="content" style="padding:0px;margin:0px 20px 0px;">
    <li style="padding:0px;margin:0px 20px 0px;"> <i> Prerequisites: </i> Stat 311. Some R is useful
    but not required. </li>
    <li style="padding:0px;margin:0px 20px 0px;"> Most of the data that you see in STAT 311 are assumed to be independent.
      However, a lot of interesting datasets include information about individual observations
      and the relationships between them. This type of data can be analyzed as networks, in which nodes
      represent individuals and edges represent relationships between them.
       Networks can be used to study interactions between social groups,
        the spread of contagious diseases, biological cycles, etc.
We will use the textbook "Statistical Analysis of Network Data," along with it's companion text
 "Statistical Analysis of Network Data in R" by Eric D. Kolaczyk. We will additionally read one or
  two papers about an application of network analysis and/or analyze a small
  network in R (based on interest of the student). </li>
</p>
</div>
